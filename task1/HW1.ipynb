{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as et\n",
    "import math\n",
    "import operator\n",
    "from statistics import mean\n",
    "\n",
    "from pymystem3 import Mystem\n",
    "\n",
    "from dictionary import *\n",
    "from document import *\n",
    "from graph import *\n",
    "\n",
    "\n",
    "def average_doc_size_in_words(docs):\n",
    "    return mean([doc.words_cnt for doc in docs])\n",
    "\n",
    "\n",
    "def average_doc_size_in_bytes(docs):\n",
    "    return mean([doc.bytes_cnt for doc in docs])\n",
    "\n",
    "\n",
    "def average_doc_text_to_html_ratio(docs):\n",
    "    return mean([doc.text_to_html_ratio for doc in docs])\n",
    "\n",
    "\n",
    "def inverse_document_frequency(dictionary, docs):\n",
    "    return {word: math.log10(len(docs) / dictionary[word].doc_cnt) for word in dictionary}\n",
    "\n",
    "\n",
    "def most_popular_word(dictionary, limit=5, get_max=True):\n",
    "    sorted_dictionary = sorted(dictionary.items(), key=operator.itemgetter(1))\n",
    "    dictionary_top = sorted_dictionary[-limit:] if get_max else sorted_dictionary[:limit]\n",
    "    max_values = [entry[1] for entry in dictionary_top]\n",
    "    return [word for (word, _) in sorted_dictionary if dictionary[word] in max_values]\n",
    "\n",
    "\n",
    "def stem_words(words, stem):\n",
    "    return stem.lemmatize(\" \".join(words))\n",
    "\n",
    "\n",
    "def parse_xml(filename):\n",
    "    docs = []\n",
    "    tree = et.parse(filename)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # TODO remove this for final result\n",
    "    cnt = 0\n",
    "\n",
    "    for child in root:\n",
    "        if child.tag == \"document\":\n",
    "            content = child[0].text\n",
    "            url = child[1].text\n",
    "            doc_id = int(child[2].text)\n",
    "            doc = Document(decode_base64_cp1251(content), doc_id, decode_base64_cp1251(url))\n",
    "            docs.append(doc)\n",
    "        # TODO remove this for final result\n",
    "        cnt += 1\n",
    "\n",
    "    return docs\n",
    "\n",
    "\n",
    "XML_FOLDER = \"byweb_for_course\"\n",
    "\n",
    "\n",
    "docs_stat = []\n",
    "mystem = Mystem()\n",
    "dictionary = Dictionary()\n",
    "graph = LinkGraph()\n",
    "\n",
    "for filename in os.listdir(XML_FOLDER):\n",
    "    if filename.endswith(\".xml\"):\n",
    "        docs = parse_xml(XML_FOLDER + os.sep + filename)\n",
    "        for doc in docs:\n",
    "            doc_stats = doc.calc_doc_stats()\n",
    "            docs_stat.append(doc_stats)\n",
    "            graph.add_document(doc_stats)\n",
    "            stemmed_words = [word.lower() for word in stem_words(doc.words, mystem) if word.isalnum()]\n",
    "            dictionary.add_doc_words(stemmed_words)\n",
    "    break  # remove it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents count: 5\n",
      "Average document length: 267.2 words\n",
      "Average document length: 40923.2 bytes\n",
      "Average text content to HTML content ratio: 0.10570340748547352\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\n    Invalid value of type 'plotly.graph_objs.Histogram' received for the 'data' property of \n        Received value: Histogram({\n    'x': [491, 138, 199, 271, 237], 'xbins': {'end': 491, 'size': 250, 'start': 0}\n})\n\n    The 'data' property is a tuple of trace instances\n    that may be specified as:\n      - A list or tuple of trace instances\n        (e.g. [Scatter(...), Bar(...)])\n      - A list or tuple of dicts of string/value properties where:\n        - The 'type' property specifies the trace type\n            One of: ['area', 'bar', 'barpolar', 'box',\n                     'candlestick', 'carpet', 'choropleth', 'cone',\n                     'contour', 'contourcarpet', 'heatmap',\n                     'heatmapgl', 'histogram', 'histogram2d',\n                     'histogram2dcontour', 'isosurface', 'mesh3d',\n                     'ohlc', 'parcats', 'parcoords', 'pie',\n                     'pointcloud', 'sankey', 'scatter',\n                     'scatter3d', 'scattercarpet', 'scattergeo',\n                     'scattergl', 'scattermapbox', 'scatterpolar',\n                     'scatterpolargl', 'scatterternary', 'splom',\n                     'streamtube', 'sunburst', 'surface', 'table',\n                     'violin', 'volume', 'waterfall']\n\n        - All remaining properties are passed to the constructor of\n          the specified trace type\n\n        (e.g. [{'type': 'scatter', ...}, {'type': 'bar, ...}])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-cbe2df5da65d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mx_axis_title\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"words\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0my_axis_title\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"documents\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m )\n\u001b[1;32m     33\u001b[0m plot_histogram(\n",
      "\u001b[0;32m<ipython-input-2-cbe2df5da65d>\u001b[0m in \u001b[0;36mplot_histogram\u001b[0;34m(data, title, x_axis_title, y_axis_title, step)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0myaxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mYAxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myaxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_axis_title\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     )\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhistogram\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/plotly/graph_objs/_figure.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, layout, frames, skip_invalid)\u001b[0m\n\u001b[1;32m    501\u001b[0m             \u001b[0;32mis\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mAND\u001b[0m \u001b[0mskip_invalid\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m         \"\"\"\n\u001b[0;32m--> 503\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_invalid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m     def add_area(\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/plotly/basedatatypes.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, layout_plotly, frames, skip_invalid)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;31m# ### Import traces ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         data = self._data_validator.validate_coerce(data,\n\u001b[0;32m--> 135\u001b[0;31m                                                     skip_invalid=skip_invalid)\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;31m# ### Save tuple of trace objects ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/_plotly_utils/basevalidators.py\u001b[0m in \u001b[0;36mvalidate_coerce\u001b[0;34m(self, v, skip_invalid)\u001b[0m\n\u001b[1;32m   2357\u001b[0m                 \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2358\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2359\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_invalid_val\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2361\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/_plotly_utils/basevalidators.py\u001b[0m in \u001b[0;36mraise_invalid_val\u001b[0;34m(self, v, inds)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtype_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0mv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             valid_clr_desc=self.description()))\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mraise_invalid_elements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minvalid_els\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: \n    Invalid value of type 'plotly.graph_objs.Histogram' received for the 'data' property of \n        Received value: Histogram({\n    'x': [491, 138, 199, 271, 237], 'xbins': {'end': 491, 'size': 250, 'start': 0}\n})\n\n    The 'data' property is a tuple of trace instances\n    that may be specified as:\n      - A list or tuple of trace instances\n        (e.g. [Scatter(...), Bar(...)])\n      - A list or tuple of dicts of string/value properties where:\n        - The 'type' property specifies the trace type\n            One of: ['area', 'bar', 'barpolar', 'box',\n                     'candlestick', 'carpet', 'choropleth', 'cone',\n                     'contour', 'contourcarpet', 'heatmap',\n                     'heatmapgl', 'histogram', 'histogram2d',\n                     'histogram2dcontour', 'isosurface', 'mesh3d',\n                     'ohlc', 'parcats', 'parcoords', 'pie',\n                     'pointcloud', 'sankey', 'scatter',\n                     'scatter3d', 'scattercarpet', 'scattergeo',\n                     'scattergl', 'scattermapbox', 'scatterpolar',\n                     'scatterpolargl', 'scatterternary', 'splom',\n                     'streamtube', 'sunburst', 'surface', 'table',\n                     'violin', 'volume', 'waterfall']\n\n        - All remaining properties are passed to the constructor of\n          the specified trace type\n\n        (e.g. [{'type': 'scatter', ...}, {'type': 'bar, ...}])"
     ]
    }
   ],
   "source": [
    "import plotly.graph_objs as go\n",
    "\n",
    "def plot_histogram(data, title, x_axis_title, y_axis_title, step):\n",
    "    histogram = go.Histogram(\n",
    "        x=data,\n",
    "        xbins=dict(\n",
    "            start=0,\n",
    "            end=max(data),\n",
    "            size=step\n",
    "        ),\n",
    "    )\n",
    "    layout = go.Layout(\n",
    "        title=title,\n",
    "        xaxis=go.layout.XAxis(title=go.layout.xaxis.Title(text=x_axis_title)),\n",
    "        yaxis=go.layout.YAxis(title=go.layout.yaxis.Title(text=y_axis_title))\n",
    "    )\n",
    "    fig = go.Figure(data=histogram, layout=layout)\n",
    "    fig.show()\n",
    "\n",
    "print(\"Total documents count: \" + str(len(docs_stat)))\n",
    "print(\"Average document length: \" + str(average_doc_size_in_words(docs_stat)) + \" words\")\n",
    "print(\"Average document length: \" + str(average_doc_size_in_bytes(docs_stat)) + \" bytes\")\n",
    "print(\"Average text content to HTML content ratio: \" + str(average_doc_text_to_html_ratio(docs_stat)))\n",
    "\n",
    "\n",
    "plot_histogram(\n",
    "    data=[stat.words_cnt for stat in docs_stat],\n",
    "    title=\"Length in words distribution\",\n",
    "    x_axis_title=\"words\",\n",
    "    y_axis_title=\"documents\",\n",
    "    step=250\n",
    ")\n",
    "plot_histogram(\n",
    "    data=[stat.bytes_cnt for stat in docs_stat],\n",
    "    title=\"Length in bytes distribution\",\n",
    "    x_axis_title=\"bytes\",\n",
    "    y_axis_title=\"documents\",\n",
    "    step=5000\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Words with largest collection frequency: \" + \n",
    "      str(most_popular_word({word: dictionary.dict[word].cnt for word in dictionary.dict})))\n",
    "print(\"Words with smallest inverse document frequency: \" +\n",
    "      str(most_popular_word(inverse_document_frequency(dictionary.dict, docs_stat), get_max=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"500px\"\n",
       "            height=\"500px\"\n",
       "            src=\"links.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fdbc452e2b0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow] *",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
