{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as et\n",
    "import math\n",
    "import operator\n",
    "from statistics import mean\n",
    "\n",
    "from pymystem3 import Mystem\n",
    "\n",
    "from dictionary import *\n",
    "from document import *\n",
    "from graph import *\n",
    "\n",
    "\n",
    "def average_doc_size_in_words(docs):\n",
    "    return mean([doc.words_cnt for doc in docs])\n",
    "\n",
    "\n",
    "def average_doc_size_in_bytes(docs):\n",
    "    return mean([doc.bytes_cnt for doc in docs])\n",
    "\n",
    "\n",
    "def average_doc_text_to_html_ratio(docs):\n",
    "    return mean([doc.text_to_html_ratio for doc in docs])\n",
    "\n",
    "\n",
    "def average_word_length(words):\n",
    "    return mean([len(word) for word in words])\n",
    "\n",
    "\n",
    "def inverse_document_frequency(dictionary, docs):\n",
    "    return {word: math.log10(len(docs) / dictionary[word].doc_cnt) for word in dictionary}\n",
    "\n",
    "\n",
    "def most_popular_word(dictionary, limit=5, get_max=True):\n",
    "    sorted_dictionary = sorted(dictionary.items(), key=operator.itemgetter(1))\n",
    "    dictionary_top = sorted_dictionary[-limit:] if get_max else sorted_dictionary[:limit]\n",
    "    max_values = [entry[1] for entry in dictionary_top]\n",
    "    return [word for (word, _) in sorted_dictionary if dictionary[word] in max_values]\n",
    "\n",
    "\n",
    "def stem_words(words, stem):\n",
    "    return stem.lemmatize(\" \".join(words))\n",
    "\n",
    "\n",
    "def parse_xml(filename):\n",
    "    docs = []\n",
    "    tree = et.parse(filename)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # TODO remove this for final result\n",
    "    cnt = 0\n",
    "\n",
    "    for child in root:\n",
    "        if child.tag == \"document\":\n",
    "            content = child[0].text\n",
    "            url = child[1].text\n",
    "            doc_id = int(child[2].text)\n",
    "            doc = Document(decode_base64_cp1251(content), doc_id, decode_base64_cp1251(url))\n",
    "            docs.append(doc)\n",
    "        # TODO remove this for final result\n",
    "        if cnt == 50:\n",
    "            break;\n",
    "        cnt += 1\n",
    "\n",
    "    return docs\n",
    "\n",
    "\n",
    "XML_FOLDER = \"byweb_for_course\"\n",
    "\n",
    "\n",
    "docs_stat = []\n",
    "mystem = Mystem()\n",
    "dictionary = Dictionary()\n",
    "graph = LinkGraph()\n",
    "\n",
    "for filename in os.listdir(XML_FOLDER):\n",
    "    if filename.endswith(\".xml\"):\n",
    "        docs = parse_xml(XML_FOLDER + os.sep + filename)\n",
    "        for doc in docs:\n",
    "            doc_stats = doc.calc_doc_stats()\n",
    "            docs_stat.append(doc_stats)\n",
    "            graph.add_document(doc_stats)\n",
    "            stemmed_words = [word.lower() for word in stem_words(doc.words, mystem) if word.isalnum()]\n",
    "            dictionary.add_doc_words(stemmed_words)\n",
    "    break  # remove it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents count: 51\n",
      "Average document length: 621.3921568627451 words\n",
      "Average document length: 47313.74509803922 bytes\n",
      "Average text content to HTML content ratio: 0.19455271362406043\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Figure' object has no attribute 'show'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-7fbe5f8a19c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mx_axis_title\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"words\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0my_axis_title\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"documents\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m )\n\u001b[1;32m     34\u001b[0m plot_histogram(\n",
      "\u001b[0;32m<ipython-input-2-7fbe5f8a19c2>\u001b[0m in \u001b[0;36mplot_histogram\u001b[0;34m(data, title, x_axis_title, y_axis_title, step)\u001b[0m\n\u001b[1;32m     17\u001b[0m     )\n\u001b[1;32m     18\u001b[0m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhistogram\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Total documents count: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs_stat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Figure' object has no attribute 'show'"
     ]
    }
   ],
   "source": [
    "from plotly.offline import init_notebook_mode, iplot\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "def plot_histogram(data, title, x_axis_title, y_axis_title, step):\n",
    "    histogram = go.Histogram(\n",
    "        x=data,\n",
    "        xbins=dict(\n",
    "            start=0,\n",
    "            end=max(data),\n",
    "            size=step\n",
    "        ),\n",
    "    )\n",
    "    layout = go.Layout(\n",
    "        title=title,\n",
    "        xaxis=go.layout.XAxis(title=go.layout.xaxis.Title(text=x_axis_title)),\n",
    "        yaxis=go.layout.YAxis(title=go.layout.yaxis.Title(text=y_axis_title))\n",
    "    )\n",
    "    fig = go.Figure(data=[histogram], layout=layout)\n",
    "    fig.show()\n",
    "\n",
    "print(\"Total documents count: \" + str(len(docs_stat)))\n",
    "print(\"Average document length: \" + str(average_doc_size_in_words(docs_stat)) + \" words\")\n",
    "print(\"Average document length: \" + str(average_doc_size_in_bytes(docs_stat)) + \" bytes\")\n",
    "print(\"Average text content to HTML content ratio: \" + str(average_doc_text_to_html_ratio(docs_stat)))\n",
    "\n",
    "\n",
    "plot_histogram(\n",
    "    data=[stat.words_cnt for stat in docs_stat],\n",
    "    title=\"Length in words distribution\",\n",
    "    x_axis_title=\"words\",\n",
    "    y_axis_title=\"documents\",\n",
    "    step=250\n",
    ")\n",
    "plot_histogram(\n",
    "    data=[stat.bytes_cnt for stat in docs_stat],\n",
    "    title=\"Length in bytes distribution\",\n",
    "    x_axis_title=\"bytes\",\n",
    "    y_axis_title=\"documents\",\n",
    "    step=5000\n",
    ")\n",
    "\n",
    "print(\"Collection stop words ratio: \" + str(dictionary.stop_words_proportion(in_collection=True)))\n",
    "print(\"Collection latin words ratio: \" + str(dictionary.latin_words_proportion(in_collection=True)))\n",
    "print(\"Dictionary latin words ratio: \" + str(dictionary.latin_words_proportion(in_collection=False)))\n",
    "print(\"Dictionary average word length: \" + str(average_word_length(dictionary.dict.keys())))\n",
    "\n",
    "print(\"Words with largest collection frequency: \" + \n",
    "      str(most_popular_word({word: dictionary.dict[word].cnt for word in dictionary.dict})))\n",
    "print(\"Words with smallest inverse document frequency: \" +\n",
    "      str(most_popular_word(inverse_document_frequency(dictionary.dict, docs_stat), get_max=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow] *",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
